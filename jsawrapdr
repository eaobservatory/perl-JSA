#!perl

=head1 NAME

jsawrap - process supplied files through the DR in a manner compatible with CADC

=head1 SYNOPSIS

  jsawrapdr --inputs=FILENAME --parameters="oracdr parameters" -persist
          --id="<instance id>"

=head1 DESCRIPTION

This program can call the pipeline processing in a CADC-compatible way. It
can either be run from the CADC data processing environment or from the
command line.

The program does the following:

 o calls dpRetrieve with the --inputs argument to retrieve the requested
   data from the appropriate location. Note that the non-CADC emulation
   of dpRetrieve will be able to handle files with full path as well
   as URIs.

 o looks at the data to determine the instrument and whether the data
   are raw or processed.

 o Sets up the pipeline environment variables

 o calls ORAC-DR or PICARD as appropriate with the supplied parameters.

 o Analyzes the pipeline products to determine suitable products and
   converts them to FITS format using the approved naming convention.

 o Calls dpCapture to allow products to be ingested.

=head1 ARGUMENTS

=over 4

=item B<--id>

Unique execution ID generated by external user. In the real system this
will be obtained from the master database table. Its value is passed
to the dpRetrieve and dpCapture executables.

=item B<--inputs>

Path to an input file containing all the files to be processed by
this instance of the pipeline. The file is passed directly to the
dpRetrieve executable and the contents must match that expected
by dpRetrieve. dpRetrieve ensures that the files are all available
in a local working directory.

=item B<--parameters>

These are the parameters that should be passed either to ORAC-DR or to
PICARD. They should be limited to a recipe name. The wrapper will determine
whether the data should be processed by PICARD or ORAC-DR. The recipe is
optional for ORAC-DR and mandatory for PICARD.

=item B<-persist>

Controls whether dpCapture should ingest the output files or simply check
them for compliance. Outside of the CADC environment dpCapture will not
do anything.

=item B<-log>

Similar to ORAC-DR C<-log> option. By default log messages are written to a
log file but the "s" option can be used to write to standard output.

=item B<-debug>

Enable debug messages.

=item B<-outdir>

Controls the output directory for all files created by the wrapper. The current
working directory is used if this argument is not supplied. Not used if -tmpdir
is used.

=item B<-tmpdir>

Use a temporary directory within the current directory for data processing.
Supercedes -outdir.

=back

=cut

use strict;
use warnings;

use Getopt::Long;
use Pod::Usage;
use File::Spec;
use File::Temp;
use Carp;
use Astro::FITS::Header;
use Astro::FITS::Header::NDF;
#use Astro::FITS::Header::CFITSIO;
use Astro::FITS::HdrTrans;

# Options
my ($help, $man, $version, $log, $persist, $id, $drparameters, $inputs, $outdir, $debug,
   $tmpdir);
my $status = GetOptions("help" => \$help,
                        "man" => \$man,
                        "version" => \$version,
                        "log=s" => \$log,
                        "persist" => \$persist,
                        "id=s" => \$id,
                        "parameters=s" => \$drparameters,
                        "inputs=s" => \$inputs,
                        "outdir=s" => \$outdir,
                        "debug" => \$debug,
                        "tmpdir" => \$tmpdir,
                       );

pod2usage(1) if $help;
pod2usage(-exitstatus => 0, -verbose => 2) if $man;

if ($version) {
  my $id = '$Id: racover.pl 14421 2007-09-05 02:37:29Z agarwal $ ';
  print "jsawrapdr - CADC compliant wrapper for JSA data processing\n";
  print " Source code revision: $id\n";
  exit;
}

# We require that STARLINK_DIR and ORAC_DIR are set
die "Do not know where the Starlink software is installed. Please set \$STARLINK_DIR."
  unless (exists $ENV{STARLINK_DIR} && -d $ENV{STARLINK_DIR});
die "Do not know where the ORAC-DR infrastructure is located. Please set \$ORAC_DIR."
  unless (exists $ENV{ORAC_DIR} && -d $ENV{ORAC_DIR});

# Check recipe parameters
if (defined $drparameters) {
  # a recipe name not an option
  if ($drparameters =~ /\s/) {
    die "DR parameters argument can not contain white space.";
  } elsif ($drparameters !~ /^[A-Z]/) {
    die "DR parameters argument must start with a capital letter";
  }
}

# Get the current working directory
my $curdir = File::Spec->rel2abs( File::Spec->curdir );

# Make sure that inputs is corrected for -outdir
if (defined $inputs) {
  $inputs = File::Spec->catfile( $curdir, $inputs )
    unless File::Spec->file_name_is_absolute;
} else {
  die "Must supply a -inputs file";
}

# Change to the output directory so that dpRetrieve will copy to this
# directory regardless of dpRetrieve not having a -outdir option at CADC

if ($tmpdir) {
  $outdir = File::Temp->newdir ( DIR => $curdir );
  log_message( "Using temporary output directory '$outdir'\n");
} elsif (defined $outdir) {
  $outdir = File::Spec->rel2abs($outdir);
  log_message( "Using specified output directory '$outdir'\n");
} else {
  $outdir = $curdir;
}
if ($outdir ne $curdir) {
  chdir($outdir) || die "Could not change directory to '$outdir'";
}

# Default the ID string since most people will not be using one
$id = "NONE" unless defined $id;

# scan the directory for plausible looking data files.
# The problem is that dpRetrieve is used to retrieve the specified data files.
# Since we do not know which files dpRetrieve retrieved we have two choices:
# 1. Die if there are any .sdf or .fits files in the directory
# 2. Scan the directory and only process files that are new (or at least
#    newer than those before calling dpRetrieve).
#
# #2 is less annoying for people but means that dpRetrieve will have to remove
# and recreate soft links if it uses soft links or use touch if the file is 
# already real. This is more work to implement but for the non-JSA user
# it will be worth it.

my %existing_files = scan_dir();

# First thing we have to do is copy the files locally by calling the
# dpRetrieve command. We hope it is in the path.
# For testing we ask this perl to run it since we know it is perl
# For CADC we rely on path.

system($^X, "-Mblib=$curdir", File::Spec->catfile($curdir,"dpRetrieve"),
       "-id", $id, "-debug", $inputs)
  && die "Could not execute dpRetrieve: $?";

# Now scan the directory again
my %post_retrieve = scan_dir();

# compare the old list with the new and return a list of files
# that should be processed
my @files = compare_file_lists( \%existing_files, \%post_retrieve );

log_message("Processing the following files:\n". join("\n",@files)."\n");

# decide whether we are using oracdr or picard

# First thing we have to do is to analyze the files to determine how things
# should be processed. If we are all FITS files then we must convert to NDF
# prior to processing. If there are some FITS and some NDF we have to decide
# whether that is okay. Read all the FITS headers and then decide whether
# they are all raw or all processed.

# FITS headers, indexed by filename
my %FITS = read_headers( @files );
if (keys %FITS == 0) {
  die "Could not open any of the supplied files to read headers: ".join(", ",@files);
} elsif (keys %FITS != @files) {
  log_warning("Some files could not be read. Continuing with those that can\n");
  @files = keys %FITS;
}

# Now count NDF vs FITS
my $nfits = 0;
my $nsdf = 0;
for my $f (@files) {
  if ($f =~ /\.f\w+$/) {
    $nfits++;
  } elsif ($f =~ /\.sdf$/) {
    $nsdf++;
  }
}

if ( ($nfits != @files) && ($nsdf != @files) ) {
  # mixed NDF and FITS
  die "There are $nfits FITS files and $nsdf NDFs out of ".@files.
    " files and this is a bit confusing";
}

# Decide on ORAC-DR vs PICARD
# FITS files are not processable by ORAC-DR and are not archived as such at CADC
# NDF are processed by orac-dr unless they have PRODUCT headers. No check is made
# for filename compliance with raw time series ICD.

# Get PRODUCT information
my ($nproduct, %products) = get_header_value( "PRODUCT", values %FITS);

my $useoracdr = 0;
if ($nfits == @files) {
  # All of them are fits so we must use picard
  log_message("Got $nfits fits - using PICARD\n");
} elsif ($nsdf == @files) {
  # we have NDFs so we need to open them and look for PRODUCT headers
  # Should we check to make sure that the PRODUCT headers match?
  log_message("Got $nsdf NDF\n");
  if ($nproduct == 0) {
    # oracdr - assume these are raw data. They may be data processed outside
    # of the DR
    $useoracdr = 1;
  }
}

# Analyze product information for non-oracdr case
if (!$useoracdr) {
  if ($nproduct == @files) {

    # check product values
    if (keys %products > 1) {
      log_warning( "Processing different products in a single run may be incorrect. (".
                   join(",",keys %products).")\n");
    }

  } else {
    die "There are $nproduct headers in ".@files.
      ", making it difficult to determine whether to run ORAC-DR or PICARD";
  }
}

# Now need to determine the ORAC_INSTRUMENT from the supplied headers
my $oracinst;
my %instruments;
for my $f (keys %FITS) {
  my $oa = get_orac_instrument( $FITS{$f} );
  die "Unable to determine ORAC_INSTRUMENT for file '$f'\n"
    unless defined $oa;
  $instruments{$oa}++;
}
if (keys %instruments > 1) {
  die "Can not process files from multiple instruments (".join(",",keys %instruments).")\n";
} else {
  # get the single instrument
  ($oracinst) = keys %instruments;
}

# Convert FITS files into NDF and update name supplied to DR


# We now have to write these files to a text file
# suitable for orac-dr to read with the -file option
my $tmpfile = File::Temp->new() or die "Could not create a temporary file";
print $tmpfile "$_\n" for @files;
close($tmpfile) or die "Error closing temp file handle";

# Configure shared environment variables
$ENV{ORAC_DATA_IN} = $outdir;
$ENV{ORAC_DATA_OUT} = $outdir;

# ORAC_PERL5LIB is only set if required
if (!exists $ENV{ORAC_PERL5LIB}) {
  $ENV{ORAC_PERL5LIB} = File::Spec->catdir( $ENV{ORAC_DIR}, "lib", "perl5" );
}

my @command;
if ($useoracdr) {
  log_message( "Using ORAC-DR\n" );

  # Instrument
  $ENV{ORAC_INSTRUMENT} = $oracinst;

  @command = ( $^X,
               File::Spec->catfile($ENV{ORAC_DIR},"bin","oracdr"),
               "-nodisplay",
               "-log","f",
               "-loop","file",
               "-file", "$tmpfile",
               "-recsuffix", "CADC",
               "-batch" );
} else {
  # We are going to need a ^file option in picard
  log_message( "Using PICARD\n" );
  @command = ( $^X,
               File::Spec->catfile($ENV{ORAC_DIR},"bin","picard"),
               "-log","f",
               @files
             );

  # PICARD needs a recipe name so we need to abort if we do not have one
  die "Processing reduced data requires the use of the -parameters option\n";

}
push(@command, $drparameters) if defined $drparameters;

# Run the command
system(@command) 
  && die "Error running pipeline: $!";

# Process NDF data products and convert them into FITS
#  - Need to filter provenance
#  - Run NDF2FITS

# Call dpRetrieve with the correct arguments

exit;

# Simply logging routine

sub log_message {
  my $message = shift;
  chomp($message);
  print STDERR "$message\n";
}

sub log_warning {
  log_message( $_[0] );
}

# scan the current directory looking for .sdf or .fits files.
# stat() files or lstat() links and return the output of stat
# as a reference to an array in a hash indexed by filename.

# %files = scan_dir();

sub scan_dir {
  
  opendir(my $dh, File::Spec->curdir)
    or croak "Could not open data directory to scan it: $!";

  my %files;
  while (defined( my $file = readdir($dh) ) ) {

    if ($file =~ /\.(sdf|fits)$/) {
      if (-l $file) {
        $files{$file} = [ lstat($file) ];
      } else {
        $files{$file} = [ stat($file) ];
      }
    }
  }
  
  closedir($dh) or croak "Could not close data directory after scan: $!";
  return %files;
}

# compare the scan before with the scan after and return anything that
# is newer or new
# my @new = compare_file_lists(\%old, \%new);

sub compare_file_lists {
  my $original = shift;
  my $after = shift;

  my @files;
  for my $current (keys %$after) {
    if (!exists $original->{$current}) {
      # must be a new file since it did not exist before
      push(@files, $current);
    } elsif ( $original->{$current}->[9] < $after->{$current}->[9]) {
      # modified since the original scan
      push(@files, $current);
    }
  }
  return @files;
}

# Read FITS headers from list of files that can either be NDF or FITS.
# Probably could be a useful helper routine in Astro::FITS::Header
# Returns hash indexed by filename
#   %headers = read_headers( @files );
# Traps files that have no headers

sub read_headers {
  my @files = @_;

  my %headers;
  for my $f (@files) {
    my $hdr;
    if ($f =~ /\.f.*$/) {
      $hdr = eval { Astro::FITS::Header::CFITSIO->new( File => $f )};
    } else {
      $hdr = eval { Astro::FITS::Header::NDF->new( File => $f )};
    }
    $headers{$f} = $hdr if defined $hdr;
  }

  return %headers;
}

# Get a header value. Return the number of headers that were found of the
# supplied name and a hash with keys containing the value and value containing
# the number of times that value was found
#
#   ($nmatches, %values) = get_header_value( "PRODUCT", @headers );

sub get_header_value {
  my ($key, @hdrs) = @_;
  my $nhits = 0;
  my %values;
  for my $h (@hdrs) {
    my $value = $h->value("PRODUCT");
    if (defined $value) {
      $values{$value}++;
      $nhits++;
    }
  }
  return ($nhits, %values);
}

# Determine the ORAC_INSTRUMENT value from a single fits header
#   $instrument = get_orac_instrument( $hdr );

sub get_orac_instrument {
  my $hdr = shift;;

  # We need the INSTRUMENT and the BACKEND 
  my %fits;
  tie %fits, "Astro::FITS::Header", $hdr;
  my $class = Astro::FITS::HdrTrans::determine_class( \%fits, undef, 1);
  die "Unable to determine header translation class for file." unless defined $class;
  my $instrument = $class->to_INSTRUMENT( \%fits );
  my $dhs = $class->to_INST_DHS( \%fits );
  my $backend = $class->to_BACKEND( \%fits );

  my $oa;
  if ($backend eq 'ACSIS' || $backend eq 'DAS' || $backend eq 'AOSC') {
    $oa = "ACSIS";
  } elsif ($instrument eq 'SCUBA2') {
    # depends on long vs short
    my $subarray = $hdr->value("SUBARRAY");
    if (defined $subarray) {
      if ($subarray =~ /^s8/) {
        $oa = "SCUBA2_LONG";
      } elsif ($subarray =~ /^s4/) {
        $oa = "SCUBA2_SHORT";
      }
    }
  } else {
    # go with instrument
    $oa = $instrument;
  }

  return $oa;
}

=head1 NOTES

ORAC-DR will be run such that the following options will be enabled
automatically:

 -nodisplay
 -log f
 -file
 -loop file
 -recsuffix CADC
 -batch

The handling of calibration options is still TBD.

PICARD is run with 

 -log f

The output from the pipeline processes is harvested automatically.

The choice of ORAC-DR or PICARD can be made by looking at the input data.
If the first file in the input file includes a PRODUCT header then it must
have been processed. Additionally, if the input is in FITS format then
it must have been processed.

=head1 ENVIRONMENT

This program requires that $STARLINK_DIR and $ORAC_DIR environment variables
are correctly defined.

Exit status is non-zero if any problem occurred during the data processing.

All files are written into the current working directory by default.

=head1 AUTHORS

Tim Jenness E<lt>t.jenness@jach.hawaii.eduE<gt>,

=head1 COPYRIGHT

Copyright (C) 2008 Science and Technology Facilities Council.
All Rights Reserved.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.

This program is distributed in the hope that it will be useful,but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place,Suite 330, Boston, MA  02111-1307, USA

=cut

