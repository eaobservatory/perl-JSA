#!perl

=head1 NAME

jsawrap - process supplied files through the DR in a manner compatible with CADC

=head1 SYNOPSIS

  jsawrapdr --inputs=FILENAME --parameters="oracdr parameters" -persist
          --id="<instance id>"

=head1 DESCRIPTION

This program can call the pipeline processing in a CADC-compatible way. It
can either be run from the CADC data processing environment or from the
command line.

The program does the following:

 o calls dpRetrieve with the --inputs argument to retrieve the requested
   data from the appropriate location. Note that the non-CADC emulation
   of dpRetrieve will be able to handle files with full path as well
   as URIs.

 o looks at the data to determine the instrument and whether the data
   are raw or processed.

 o Sets up the pipeline environment variables

 o calls ORAC-DR or PICARD as appropriate with the supplied parameters.

 o Analyzes the pipeline products to determine suitable products and
   converts them to FITS format using the approved naming convention.

 o Calls dpCapture to allow products to be ingested.

=head1 ARGUMENTS

=over 4

=item B<--id>

Unique execution ID generated by external user. In the real system this
will be obtained from the master database table. Its value is passed
to the dpRetrieve and dpCapture executables.

=item B<--inputs>

Path to an input file containing all the files to be processed by
this instance of the pipeline. The file is passed directly to the
dpRetrieve executable and the contents must match that expected
by dpRetrieve. dpRetrieve ensures that the files are all available
in a local working directory.

=item B<--parameters>

These are the parameters that should be passed either to ORAC-DR or to
PICARD. They should be limited to a recipe name. The wrapper will determine
whether the data should be processed by PICARD or ORAC-DR. The recipe is
optional for ORAC-DR and mandatory for PICARD.

=item B<-persist>

Controls whether dpCapture should ingest the output files or simply check
them for compliance. Outside of the CADC environment dpCapture will not
do anything.

=item B<-log>

Similar to ORAC-DR C<-log> option. By default log messages are written to a
log file but the "s" option can be used to write to standard output.

=item B<-debug>

Enable debug messages.

=item B<-outdir>

Controls the output directory for all files created by the wrapper. The current
working directory is used if this argument is not supplied. Not used if -tmpdir
is used.

=item B<-tmpdir>

Use a temporary directory within the current directory for data processing.
Supercedes -outdir.

=back

=head1 QUESTIONS

These questions relate mainly to non-CADC usage:

- If a file lacks a PRODUCT and is an NDF it is currently assumed to be raw.
  Should the wrapper check filename convention? Should it check provenance?

- If a FITS file does not match the CADC naming convention should it still
  be processed by picard? Currently they are skipped.

- If an NDF does have a PRODUCT header but non-standard filename is that okay?
  Note that dpCapture only looks for standard filenames and the ndf2fits
  routine will not process unrecognized filenames.


=cut

use strict;
use warnings;

use FindBin;

use Getopt::Long;
use Pod::Usage;
use File::Spec;
use File::Temp;
use Carp;
use Astro::FITS::Header;
use Astro::FITS::Header::NDF;
use Astro::FITS::Header::CFITSIO;
use Astro::FITS::HdrTrans;

use JSA::Starlink qw/ check_star_env run_star_command prov_update_parent_path /;
use JSA::Command qw/ run_command /;
use JSA::Convert qw/ convert_to_fits convert_to_ndf /;
use JSA::Files qw/ compare_file_lists scan_dir looks_like_cadcfile /;

# Add the path for this routine to the full path. This will allow
# dpCapture and dpRetrieve to be found in emulation. Add to the end of 
# path so that the real CADC versions will be found
BEGIN {
  my $newpath = $FindBin::RealBin;
  $newpath .= ":". $FindBin::Bin if $FindBin::Bin ne $FindBin::RealBin;
  if (exists $ENV{PATH}) {
    $ENV{PATH} = $ENV{PATH} . ":". $newpath;
  } else {
    $ENV{PATH} = $newpath;
  }
}

# All products that should be exported.
our @PRODUCTS = qw/ cube /;
our %PRODS = map { $_ => undef } @PRODUCTS;

# Options
my ($help, $man, $version, $log, $persist, $id, $drparameters, $inputs, $outdir, $debug,
   $tmpdir);
my $status = GetOptions("help" => \$help,
                        "man" => \$man,
                        "version" => \$version,
                        "log=s" => \$log,
                        "persist" => \$persist,
                        "id=s" => \$id,
                        "parameters=s" => \$drparameters,
                        "inputs=s" => \$inputs,
                        "outdir=s" => \$outdir,
                        "debug" => \$debug,
                        "tmpdir" => \$tmpdir,
                       );

pod2usage(1) if $help;
pod2usage(-exitstatus => 0, -verbose => 2) if $man;

if ($version) {
  my $id = '$Id: racover.pl 14421 2007-09-05 02:37:29Z agarwal $ ';
  print "jsawrapdr - CADC compliant wrapper for JSA data processing\n";
  print " Source code revision: $id\n";
  exit;
}

# We require that STARLINK_DIR and ORAC_DIR are set
check_star_env( "ORAC" );

# Check recipe parameters
if (defined $drparameters) {
  # a recipe name not an option
  if ($drparameters =~ /\s/) {
    die "DR parameters argument can not contain white space.";
  } elsif ($drparameters !~ /^[A-Z]/) {
    die "DR parameters argument must start with a capital letter";
  }
}

# Get the current working directory
my $curdir = File::Spec->rel2abs( File::Spec->curdir );

# Make sure that inputs is corrected for -outdir
if (defined $inputs) {
  $inputs = File::Spec->catfile( $curdir, $inputs )
    unless File::Spec->file_name_is_absolute;
} else {
  die "Must supply a -inputs file";
}

# Change to the output directory so that dpRetrieve will copy to this
# directory regardless of dpRetrieve not having a -outdir option at CADC

if ($tmpdir) {
  $outdir = File::Temp->newdir ( DIR => $curdir );
  log_message( "Using temporary output directory '$outdir'\n");
} elsif (defined $outdir) {
  $outdir = File::Spec->rel2abs($outdir);
  log_message( "Using specified output directory '$outdir'\n");
} else {
  $outdir = $curdir;
}
if ($outdir ne $curdir) {
  chdir($outdir) || die "Could not change directory to '$outdir'";
}

# Default the ID string since most people will not be using one
$id = "NONE" unless defined $id;

# scan the directory for plausible looking data files.
# The problem is that dpRetrieve is used to retrieve the specified data files.
# Since we do not know which files dpRetrieve retrieved we have two choices:
# 1. Die if there are any .sdf or .fits files in the directory
# 2. Scan the directory and only process files that are new (or at least
#    newer than those before calling dpRetrieve).
#
# #2 is less annoying for people but means that dpRetrieve will have to remove
# and recreate soft links if it uses soft links or use touch if the file is 
# already real. This is more work to implement but for the non-JSA user
# it will be worth it.

my %existing_files = scan_dir();

# First thing we have to do is copy the files locally by calling the
# dpRetrieve command. We hope it is in the path.
# For testing we ask this perl to run it since we know it is perl
# For CADC we rely on path.

run_command(File::Spec->catfile($curdir,"dpRetrieve"),
            "-id", $id, "-debug", $inputs);

# Now scan the directory again
my %post_retrieve = scan_dir();

# compare the old list with the new and return a list of files
# that should be processed
my @files = compare_file_lists( \%existing_files, \%post_retrieve );

log_message("Processing the following files:\n". join("\n",@files)."\n");

# decide whether we are using oracdr or picard

# First thing we have to do is to analyze the files to determine how things
# should be processed. If we are all FITS files then we must convert to NDF
# prior to processing. If there are some FITS and some NDF we have to decide
# whether that is okay. Read all the FITS headers and then decide whether
# they are all raw or all processed.

# Now count NDF vs FITS
my $nfits = 0;
my $nsdf = 0;
for my $f (@files) {
  if ($f =~ /\.f\w+$/) {
    $nfits++;
  } elsif ($f =~ /\.sdf$/) {
    $nsdf++;
  }
}

if ( ($nfits != @files) && ($nsdf != @files) ) {
  # mixed NDF and FITS
  die "There are $nfits FITS files and $nsdf NDFs out of ".@files.
    " files and this is a bit confusing";
}

# FITS headers, indexed by filename
my %FITS = read_headers( @files );
if (keys %FITS == 0) {
  die "Could not open any of the supplied files to read headers: ".join(", ",@files);
} elsif (keys %FITS != @files) {
  log_warning("Some files could not be read. Continuing with those that can\n");
  @files = keys %FITS;
}

# Decide on ORAC-DR vs PICARD
# FITS files are not processable by ORAC-DR and are not archived as such at CADC
# NDF are processed by orac-dr unless they have PRODUCT headers. No check is made
# for filename compliance with raw time series ICD.

# Get PRODUCT information
my ($nproduct, %products) = get_header_value( "PRODUCT", values %FITS);

my $useoracdr = 0;
if ($nfits == @files) {
  # All of them are fits so we must use picard
  log_message("Got $nfits fits - using PICARD\n");
} elsif ($nsdf == @files) {
  # we have NDFs so we need to open them and look for PRODUCT headers
  # Should we check to make sure that the PRODUCT headers match?
  log_message("Got $nsdf NDF\n");
  if ($nproduct == 0) {
    # oracdr - assume these are raw data. They may be data processed outside
    # of the DR
    $useoracdr = 1;
  }
}

# Analyze product information for non-oracdr case
if (!$useoracdr) {
  if ($nproduct == @files) {

    # check product values
    if (keys %products > 1) {
      log_warning( "Processing different products in a single run may be incorrect. (".
                   join(",",keys %products).")\n");
    }
  } elsif ($nproduct == 0) {
    die "None of the input files contained PRODUCT FITS headers";

  } else {
    die "There are $nproduct headers in ".@files.
      ", making it difficult to determine whether to run ORAC-DR or PICARD";
  }
}

# Now need to determine the ORAC_INSTRUMENT from the supplied headers
my $oracinst;
if ($useoracdr) {
  my %instruments;
  for my $f (keys %FITS) {
    my $oa = get_orac_instrument( $FITS{$f} );
    die "Unable to determine ORAC_INSTRUMENT for file '$f'\n"
      unless defined $oa;
    $instruments{$oa}++;
  }
  if (keys %instruments > 1) {
    die "Can not process files from multiple instruments (".join(",",keys %instruments).")\n";
  } else {
    # get the single instrument
    ($oracinst) = keys %instruments;
  }
}

# Convert FITS files into NDF and update name supplied to DR
# We could do this before we read the FITS headers but it is more efficient to
# delay conversion in case some other error condition is hit first. Conversion
# will take a non-trivial amount of time
if ($nfits > 0) {
  my @new;
  for my $f (@files) {
    if (looks_like_cadcfile( $f )) {
      my $out = convert_to_ndf( $f );
      if ($out) {
        push(@new, $out );
      }
    } else {
      log_warning( "File $f does not use the CADC naming convention. Skipping.\n");
    }
  }
  if (@new) {
    @files = @new;
  } else {
    die "No files left to process after conversion to NDF";
  }
}

# We now have to write these files to a text file
# suitable for orac-dr to read with the -file option
my $tmpfile = File::Temp->new() or die "Could not create a temporary file";
print $tmpfile "$_\n" for @files;
close($tmpfile) or die "Error closing temp file handle";

# Configure shared environment variables
$ENV{ORAC_DATA_IN} = $outdir;
$ENV{ORAC_DATA_OUT} = $outdir;

# ORAC_PERL5LIB is only set if required
if (!exists $ENV{ORAC_PERL5LIB}) {
  $ENV{ORAC_PERL5LIB} = File::Spec->catdir( $ENV{ORAC_DIR}, "lib", "perl5" );
}

my @drcommand;
if ($useoracdr) {
  log_message( "Using ORAC-DR\n" );

  # Instrument
  $ENV{ORAC_INSTRUMENT} = $oracinst;

  @drcommand = ( $^X,
               File::Spec->catfile($ENV{ORAC_DIR},"bin","oracdr"),
               "-nodisplay",
               "-log","fs",
               "-loop","file",
               "-file", "$tmpfile",
               "-recsuffix", "CADC",
               "-batch" );

  # The recipe comes at the end and is optional
  push(@drcommand, $drparameters) if defined $drparameters;

} else {
  # We are going to need a ^file option in picard
  log_message( "Using PICARD\n" );

  # PICARD needs a recipe name so we need to abort if we do not have one
  die "Processing reduced data requires the use of the -parameters option\n"
    unless (defined $drparameters && $drparameters =~ /[A-Z]/);

  # Picard only uses a recipe name from drparameters
  @drcommand = ( $^X,
               File::Spec->catfile($ENV{ORAC_DIR},"bin","picard"),
               "-log","f",
               $drparameters,
               @files
             );

}

# Run the DR command.
# We need to decide whether a partial execution of the DR should result in
# file ingestion.

run_command(@drcommand);

# Process NDF data products and convert them into FITS
#  - Need to filter provenance
#  - Run NDF2FITS

# scan the directory again
my %post_process = scan_dir();
my @drfiles = compare_file_lists( \%post_retrieve, \%post_process );

# Now look for all files that have product headers that are okay
my %drhdrs = read_headers( @drfiles );

for my $f (sort keys %drhdrs) {
  my $obstype = $drhdrs{$f}->value( "OBS_TYPE" );
  if (defined $obstype && $obstype =~ /science/i) {
    print "Analyzing file headers for DR product in $f\n";
    my $prod = $drhdrs{$f}->value( "PRODUCT" );
    if (defined $prod && exists $PRODS{$prod}) {
      # is exportable so first fix up provenance
      prov_update_parent_path( $f );

      # Modify the WCS attributes so that we generate the correct
      # FITS headers regardless of how the pipeline was configured.
      set_wcs_attribs( $f );

      # then convert to fits
      my $outfile = convert_to_fits( $f );

      # Now need to fix up PRODUCT names in extensions
      update_fits_product( $outfile );
    }
  }
}

# Call dpRetrieve with the correct arguments

run_command(File::Spec->catfile($curdir,"dpCapture"),
       "-id", $id, "-debug");

exit;

#############################################################################################

# Simple logging routine

sub log_message {
  my $message = shift;
  chomp($message);
  print STDERR "$message\n";
}

sub log_warning {
  log_message( $_[0] );
}


# Read FITS headers from list of files that can either be NDF or FITS.
# Probably could be a useful helper routine in Astro::FITS::Header
# Returns hash indexed by filename
#   %headers = read_headers( @files );
# Traps files that have no headers

sub read_headers {
  my @files = @_;

  my %headers;
  for my $f (@files) {
    my $hdr;
    if ($f =~ /\.f.*$/) {
      $hdr = eval { Astro::FITS::Header::CFITSIO->new( File => $f )};
    } else {
      $hdr = eval { Astro::FITS::Header::NDF->new( File => $f )};
    }
    $headers{$f} = $hdr if defined $hdr;
  }

  return %headers;
}

# Get a header value. Return the number of headers that were found of the
# supplied name and a hash with keys containing the value and value containing
# the number of times that value was found
#
#   ($nmatches, %values) = get_header_value( "PRODUCT", @headers );

sub get_header_value {
  my ($key, @hdrs) = @_;
  my $nhits = 0;
  my %values;
  for my $h (@hdrs) {
    my $value = $h->value($key);
    if (defined $value) {
      $values{$value}++;
      $nhits++;
    }
  }
  return ($nhits, %values);
}

# Determine the ORAC_INSTRUMENT value from a single fits header
#   $instrument = get_orac_instrument( $hdr );

sub get_orac_instrument {
  my $hdr = shift;;

  # We need the INSTRUMENT and the BACKEND 
  my %fits;
  tie %fits, "Astro::FITS::Header", $hdr;
  my $class = Astro::FITS::HdrTrans::determine_class( \%fits, undef, 1);
  die "Unable to determine header translation class for file." unless defined $class;
  my $instrument = $class->to_INSTRUMENT( \%fits );
  my $dhs = $class->to_INST_DHS( \%fits );
  my $backend = $class->to_BACKEND( \%fits );

  my $oa;
  if ($backend eq 'ACSIS' || $backend eq 'DAS' || $backend eq 'AOSC') {
    $oa = "ACSIS";
  } elsif ($instrument eq 'SCUBA2') {
    # depends on long vs short
    my $subarray = $hdr->value("SUBARRAY");
    if (defined $subarray) {
      if ($subarray =~ /^s8/) {
        $oa = "SCUBA2_LONG";
      } elsif ($subarray =~ /^s4/) {
        $oa = "SCUBA2_SHORT";
      }
    }
  } else {
    # go with instrument
    $oa = $instrument;
  }

  return $oa;
}

# Routine updates the EXTENSION FITS Headers of the .fits file to store modified
# product headers. Product is derived by adding _EXTNAME

sub update_fits_product {
  my $file = shift;

  my $status = 0;
  my $ifits = Astro::FITS::CFITSIO::open_file( $file, Astro::FITS::CFITSIO::READWRITE(), $status );

  $ifits->get_num_hdus( my $numhdus, $status );

  # we only have to modify extensions
  if ($numhdus > 1) {
    # Read PRODUCT from PRIMARY header
    $ifits->read_key( Astro::FITS::CFITSIO::TSTRING(), "PRODUCT", my $prodref, my $pcomment, $status );
    for my $i (2..$numhdus) {
      last if $status != 0;
      $ifits->movabs_hdu( $i, my $hdutype, $status );
      next unless $hdutype == Astro::FITS::CFITSIO::IMAGE_HDU();

      # Get the EXTNAME
      $ifits->read_key( Astro::FITS::CFITSIO::TSTRING(), "EXTNAME", my $extname, undef, $status );
      if ($status != 0) {
        $status = 0;
        next;
      }

      # Need thing after last dot
      $extname = (split(/\./,$extname))[-1];

      # set the new value for use PRODUCT (lower case version of extension)
      my $newprod = $prodref . lc("_$extname");

      $ifits->update_key( Astro::FITS::CFITSIO::TSTRING(), "PRODUCT", $newprod, undef, $status );
      $status = 0;
    }
  }

  $ifits->close_file( $status );
  
}

sub set_wcs_attribs {
  my $infile = shift;
  check_star_env( "KAPPA", "wcsattrib" );

  my @args = ( File::Spec->catfile( $ENV{KAPPA_DIR}, "wcsattrib" ),
               "NDF=$infile",
               "MODE=MSet",
               "SETTING='System(3)=FREQ,StdOfRest=BARY,System(1)=FK5'",
             );

  run_star_command( @args );
  return;
}


=head1 NOTES

ORAC-DR will be run such that the following options will be enabled
automatically:

 -nodisplay
 -log f
 -file
 -loop file
 -recsuffix CADC
 -batch

The handling of calibration options is still TBD.

PICARD is run with 

 -log f

The output from the pipeline processes is harvested automatically.

The choice of ORAC-DR or PICARD can be made by looking at the input data.
If the first file in the input file includes a PRODUCT header then it must
have been processed. Additionally, if the input is in FITS format then
it must have been processed.

=head1 ENVIRONMENT

This program requires that $STARLINK_DIR and $ORAC_DIR environment variables
are correctly defined.

Exit status is non-zero if any problem occurred during the data processing.

All files are written into the current working directory by default.

=head1 AUTHORS

Tim Jenness E<lt>t.jenness@jach.hawaii.eduE<gt>,

=head1 COPYRIGHT

Copyright (C) 2008 Science and Technology Facilities Council.
All Rights Reserved.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.

This program is distributed in the hope that it will be useful,but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place,Suite 330, Boston, MA  02111-1307, USA

=cut

