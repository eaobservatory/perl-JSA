#!/usr/bin/env perl

=head1 NAME

dpRetrieve - Retrieve files in manner consistent with CADC implementation

=head1 SYNOPSIS

    dpRetrieve --inputs=name_of_filelist

=head1 DESCRIPTION

The CADC processing environment provides a command for retrieving files
from the CADC archive using URIs provided in a text file. The command
written here is a compatibility version to allow the data processing
system to be tested outside of the CADC environment.

The test version of dpRetrieve can work on file URIs, full paths
to local files, or file names relative to the value of the
ORAC_DATA_IN environment variable. Current working directory is used
if ORAC_DATA_IN is unset or if the file does not exist in that directory.

If the files are present in the current working directory they will be
touched so that the DR wrapper can recognize that the file is to be
processed. If they are present through a soft link in the local
directory the link is removed and recreated for the same reason. If
the file is in a remote directory a soft link is created. If the file or
soft link pre-exists a check is made to ensure that the new file is the
same as the old file.

=head1 ARGUMENTS

=over 4

=item B<-debug>

Write informational messages to standard error. Not supported by CADC.

=item B<--outdir>

Controls the directory used to write files that have been
retrieved. Files are located using current working directory (if they
are path-less) regardless of the setting of this parameter. Defaults
to current working directory. This argument is not compatible with
CADC and should not be used by the wrapper script.

=item B<--inputs>

The name of a text file containing either file URIs or path to a file.
If the file contains http: URLs they are immediately given to
curl without further analysis.

If the file contains strings starting with a "%" they are assumed to
be file ids or patterns of file ids. The leading "%" is stripped and
the remainder is either retrieved directly from CADC or else any
wild-carding is expanded to file IDs.

=cut

use strict;
use warnings;

use Getopt::Long;
use Pod::Usage;
use File::Spec;
use File::HomeDir;
use File::Temp;
use Carp;
use URI;
use Compress::Zlib;

# Work out where we are so that we can run from a build directory
# and still find the JSA classes
use FindBin;
use lib $FindBin::RealBin."/lib";

use JSA::Files qw/uri_to_file/;
use JSA::Command qw/run_command/;

# Options
my ($help, $man, $version, $inputs, $debug, $outdir );
my $status = GetOptions(
    "help" => \$help,
    "man" => \$man,
    "version" => \$version,
    "inputs=s" => \$inputs,
    "outdir=s" => \$outdir,
    "debug" => \$debug,
);

pod2usage(1) if $help;
pod2usage(-exitstatus => 0, -verbose => 2) if $man;

if ($version) {
    print "dpRetrieve - compatibility retrieval script for jsawrapdr\n";
    exit;
}

# output directory defaulting
if ($outdir) {
    print STDERR "Overriding output directory with $outdir\n"
      if $debug;
}
else {
    $outdir = File::Spec->curdir;
}

# absolute output directory name for error messages
my $absdir = File::Spec->rel2abs($outdir);

# open the file and read all the lines
my $file = $inputs;
die "dpRetrieve: No file supplied so unable to retrieve any data files"
    unless defined $file;

open (my $fh, "<", $file)
    or die "Could not open supplied filename '$file': $!";

my @lines = <$fh>;

close($fh) or die "Could not close file '$file': $!";

# have three branches here. There is a "it looks like a http url so we use curl directly",
# a "have file_ids so convert to urls" and "it looks local so we'll just copy"

if ($lines[0] =~ /^\s*http/) {
    # looks like a collection of URLs.
    geturls(@lines);
}
elsif ($lines[0] =~ /^\%/) {
    # Keep a list of all file ids to be retrieved
    my @file_ids;

    for my $id (@lines) {
        # trim leading % and leading/trailing whitespace
        chomp($id);
        $id =~ s/\#.*//; # remove comment
        $id =~ s/\s*$//;
        $id =~ s/^\s*\%//;
        next unless length($id) > 0;

        # if we still have a % we assume it is a wildcard for jcmtInfo
        if ($id =~ /\%/) {
            # Escape the wildcard, else jcmtInfo URL returns nothing.
            $id =~ s/\%/%25/g;

            # Need a URL
            my $url = 'http://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/cadcbin/jcmtInfo?file=' . $id;

            $debug and print "Fetching $url ...\n";
            my ($stdout, $stderr, $status) = run_command( "curl",
                                                          "--silent",
                                                          "--location",
                                                          $url);
            # each line should be a new file id
            push( @file_ids, @$stdout );
        }
        else {
            # Just a straight file id
            push(@file_ids, $id);
        }
    }

    # Now convert the file ids to a url at CADC
    my @urls = map { "http://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/data/auth/JCMT/".$_ } @file_ids;

    # and retrieve the data
    geturls(@urls);
}
else {
    for my $line (@lines) {
        my $fullpath = parse_retrieve_line($line);
        next unless defined $fullpath;

        # see if that path exists
        if (-e $fullpath) {
            # split into a directory and a filename
            my ($vol, $dir, $file) = File::Spec->splitpath($fullpath);

            # output location
            $file = File::Spec->catdir($outdir, $file);

            # see if it exists already in the current dir
            if (-e $file) {
                # We first have to decide whether it is the same
                # file or note
                my @statcurr = stat($file);
                my @statnew  = stat($fullpath);

                my $same = 1;
                for my $i (0..$#statcurr) {
                    if ($statcurr[$i] != $statnew[$i]) {
                        $same = 0;
                        last;
                    }
                }
                if (!$same) {
                    die "Unable to retrieve file '$fullpath' because a file named '$file' already exists in the retrieve directory ($absdir) and it is different";
                }

                # we know they are the same file
                if (-l $file) {
                    # remove the link and remake it
                    if (unlink $file) {
                        symlink $fullpath, $file
                            or die "Could not make soft link to '$file' in retrieve directory ($absdir)\n";

                        print STDERR "Re-making soft link for '$file'\n"
                            if $debug;
                    }
                }
                else {
                    # it is a real file locally and it is the same so we touch
                    # it to allow the wrapper script to know that it is required
                    my $atime = time;
                    my $mtime = $atime;

                    utime($atime, $mtime, $file)
                        or die "Error touching file '$file' in current directory ($absdir)";

                    print STDERR "Touching pre-existing file '$file'\n"
                        if $debug;
                }
            }
            else {
                # make a soft link
                symlink $fullpath, $file
                    or print STDERR "Could not make soft link to '$file' in current directory ($absdir)\n";
                print STDERR "Making new soft link for file '$file'\n";
            }
        }
        else {
          print STDERR "File '$fullpath' does not seem to exist\n";
        }
    }
}

exit 0;

# Converts a line retrieved from an "inputs" file into a full path
# Recognizes file:// URLs
# Recognizes ad:JCMT/ URIs
# Recognizes fulle path to file /xxx/yy
# For path-less strings prepends $ORAC_DATA_IN
#   or current dir if not set
# Comments (# xxx) are removed

sub parse_retrieve_line {
    my $line = shift;
    chomp($line);
    $line =~ s/\#.*//;
    return unless $line =~ /\w/;

    my $path;

    # Try it as a URI
    my $uri = URI->new($line);
    if (!$uri->scheme) {
        $path = $line;
    }
    elsif ($uri->scheme eq 'ad') {
        $path = uri_to_file($line);
    }
    elsif ($uri->scheme eq 'file') {
        $path = $uri->path;
    }
    else {
        croak "Unsupported URI scheme '".$uri->scheme."'";
    }

    # see if we need to attach a directory. We do this if the
    # file is relative.
    if (!File::Spec->file_name_is_absolute($path)) {
        # no directory so we guess ORAC_DATA_IN, else it will have
        # to be current working directory. We check in ORAC_DATA_IN
        if (exists $ENV{ORAC_DATA_IN} &&
                defined $ENV{ORAC_DATA_IN} &&
                -d $ENV{ORAC_DATA_IN}) {
            my $newpath = File::Spec->catdir($ENV{ORAC_DATA_IN}, $path);
            $path = $newpath if -e $newpath;
        }
    }
    return $path;
}

# Reads .cadcuser file and returns list of $user, $password.
# Empty list if no file or if file does not have a first line of user:password

sub get_cadc_user_info {
    my $userinfo = File::Spec->catfile(File::HomeDir->my_home, ".cadcuser");
    my @results;
    if (open(my $CADC, "<", $userinfo)) {
        print "Reading CADC user information\n";
        my $line = <$CADC>;
        chomp($line);
        if (defined $line && $line =~ /\w:/) {
            $line =~ s/\s+$//;
            $line =~ s/^\s+//;
            push(@results, split /:/, $line, 2);
            print "Found CADC user $results[0]\n" if $debug;
        }
        close($CADC);
    }
    return @results;
}

# Given an array of URLs, retrieves them
# Currently uses curl through run_command. Tsk tsk.
# Have not got round to using LWP or WWW::Curl yet.

sub geturls {
    # Read the URLs and remove blank entries
    my @urls;
    for my $arg (@_) {
        chomp($arg);
        $arg =~ s/\#.*//; # remove comment
        $arg =~ s/\s*$//;
        $arg =~ s/^\s*//;
        push(@urls, $arg) if length($arg) > 0;
    }

    # See if we have a .cadcuser file
    my ($user, $password) = get_cadc_user_info();

    # use curl
    my @curl_args;
    if (defined $user && defined $password) {
        push(@curl_args, "--user", "$user:$password");
    }

    for my $url (@urls) {
        my $temp_fh = File::Temp->new('TEMPLATE' => join '-', '_temp' , $$ , 'XXXXXXXX');
        $temp_fh->unlink_on_destroy(1);
        my $tmpfile = $temp_fh->filename();

        $debug and print "Fetching $url ...\n";
        my ($stdout, $stderr, $status) = run_command( "curl",
                                                      @curl_args,
                                                      "--location",
                                                      "-o", $tmpfile,
                                                      "-v","--silent",
                                                      $url);
        print join("\n",@$stdout) if $stdout;
        print "Errors: ". join("\n",@$stderr) if ($stderr && $status);

        # Get the filename
        my $outfile;
        for my $out (@$stderr) {
            if ($out =~ /filename=(.*)\s*$/) {
                $outfile = $1;
            }
        }

        if (defined $outfile) {
            print "Retrieved file '$outfile'\n";

            # gunzip if necessary
            if ($outfile =~ /\.gz$/) {
                $outfile =~ s/\.gz$//;
                print "Gunzipping to $outfile\n";
                # Open the gzipped file for read
                my $gz = gzopen($tmpfile, "rb");
                die "Could not open gzipped file" unless defined $gz;

                # and the output file for write
                open(my $outfh, ">", $outfile) or die "Error opening output file $outfile: $!";

                while (1) {
                    my $buffer;
                    my $bytesread = $gz->gzread($buffer);
                    if ($bytesread > 0) {
                        syswrite($outfh, $buffer, $bytesread);
                    } elsif ( $bytesread == 0 ) {
                        last;
                    } else {
                        die "Error reading bytes from gzipped file";
                    }
                }
                close($outfh);
            }
            else {
                # simple rename
                rename($tmpfile, $outfile);
            }
        }
        else {
            print STDERR "WARNING: Could not determine local file name\n";
        }
    }
}


=head1 AUTHORS

Tim Jenness E<lt>t.jenness@jach.hawaii.eduE<gt>,

=head1 COPYRIGHT

Copyright (C) 2008, 2010 Science and Technology Facilities Council.
All Rights Reserved.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.

This program is distributed in the hope that it will be useful,but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place,Suite 330, Boston, MA  02111-1307, USA

=cut
